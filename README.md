# mydatatoolkit
A toolkit for data scientist to get work done faster, easier and in a smarter way.

Interesting Open Source Projects for Data Scientists  
Author: [shaurya](https://www.linkedin.com/in/shaurya-uppal/)

1.  Scheduler for Automation  
    a. Airflow ([Documentation](https://airflow.apache.org/))

2.  NLP Support  
    a. [Hugging Face](https://huggingface.co/)  
    b. [Simple Representation](https://github.com/AliOsm/simplerepresentations): Easy-to-use text representations extraction library based on the Transformers library.  
    c. [Simple Transformer:](https://github.com/ThilinaRajapakse/simpletransformers) ([Website](https://simpletransformers.ai/)) Transformers for Classification, NER, QA, Language Modelling, Language Generation, T5, Multimodal, and Conversational AI  
    d. [Facebook FastText](https://github.com/facebookresearch/fastText): Library for fast text representation and classification.  
    e. [Bert-as-service:](https://github.com/hanxiao/bert-as-service) Mapping a variable-length sentence to a fixed-length vector using BERT model  
    f. [spaCy](https://spacy.io/)  
    g. [TextBlob](https://textblob.readthedocs.io/en/dev/) is a Python (2 and 3) library for processing textual data. It provides a simple API for diving into common natural language processing (NLP) tasks such as part-of-speech tagging, noun phrase extraction, sentiment analysis, classification, translation, and more.  
    h. [eXtreme classification](http://manikvarma.org/downloads/XC/XMLRepository.html): Multi-Label Classification with as big as 10M label set.  
    i. [TextHero](https://texthero.org/): Texthero is a python package to work with text data efficiently. It empowers NLP developers with a tool to quickly understand any text-based dataset and it provides a solid pipeline to clean and represent text data, from zero to hero.  
    j. [Gensim](https://radimrehurek.com/gensim/index.html): A library for topic modeling, document indexing, and similarity retrieval with large corpora. All algorithms in Gensim are memory independent, w.r.t., the corpus size, and hence, it can process input larger than RAM.  
    k. [Adapterhub](https://adapterhub.ml/)  
    l. [KTrain](https://github.com/amaiya/ktrain): Zero Shot Learning Text Classification  
    m. [DeText](https://github.com/linkedin/detext): DeText: A Deep Neural Text Understanding Framework for Ranking and Classification  
    n. [Spark-NLP](https://nlp.johnsnowlabs.com/)  
    o. [Date Parser](https://github.com/scrapinghub/dateparser): Support for almost every existing date format: absolute dates, relative dates (“two weeks ago” or “tomorrow”), timestamps, etc.  
    p. [Contraction](https://github.com/kootenpv/contractions): Solve contractions like you’re -> you are

3.  Managing Data Science Projects  
    a. [DVC:](https://dvc.org/) Data Version Control for data science models and large size datasets  
    b. Metaflow open-sourced by Netflix ([Github Link](https://github.com/Netflix/metaflow)) ([Documentation](https://metaflow.org/)) ([Medium Article](https://towardsdatascience.com/learn-metaflow-in-10-mins-netflixs-python-r-framework-for-data-scientists-2ef124c716e4))  
    c. [CML](https://cml.dev/): Continuous Machine Learning (CML) is CI/CD for Machine Learning Projects  
    d. [https://s3tools.org/s3cmd](https://s3tools.org/s3cmd)

4.  Model Inferencing / Exposing End Point  
    a. [BentoML](https://docs.bentoml.org/en/latest/): Turn trained ML model into production API endpoint with a few lines of code  
    b. [FastAPI:](https://fastapi.tiangolo.com/) It is a python API microframework, widely used in data science for model inferencing, and is stated as a better and faster version of Flask.

5.  Useful Data Sources  
    a. 10,000 Most Common Words based on Google’s Trillion Word Corpus: ([Data Source Link](https://github.com/first20hours/google-10000-english)) - This repo is a good dictionary source to get rid of the most common word of different lengths. They have long, medium, short, and with or without profanity most common words in the dictionary.  
    b. [English Profanity Dictionary](https://raw.githubusercontent.com/shauryauppal/DictionaryUtils/master/english_profanity_google.txt): English profanity words identified by Google.

6.  Training DeepLearning Models  
    a. Ludwig by Uber ([Github Link](https://github.com/uber/ludwig)) ([Documentation](http://ludwig.ai/)) is a toolbox built on top of TensorFlow that allows us to train and test deep learning models without the need to write code.

7.  Notebooks other than Jupyter  
    a. Google Colab ([Direct Link](https://colab.research.google.com/)) is a Jupyter Notebook hosted by Google that provides free GPU and TPU environments to train models  
    b. Polynote open-sourced by Netflix ([Github Link](https://github.com/polynote/polynote)) [(Link)](https://polynote.org/). Polynote is an experimental polyglot notebook environment. Currently, it supports Scala and Python (with or without Spark), SQL, and Vega.

8.  Extract Text from PDFs  
    a. Camelot [(Documentation)](https://camelot-py.readthedocs.io/en/master/)  
    b. Tabula [(Github Link)](https://github.com/chezou/tabula-py)  
    c. Tika-Python [(Github Link)](https://github.com/chrismattmann/tika-python) [(Documentation)](https://tika.apache.org/)  
    d. TaBERT ([Documentation](https://ai.facebook.com/blog/tabert-a-new-model-for-understanding-queries-over-tabular-data/))  
    e. Keras-RetinaNet

9.  Miscellaneous  
    a. [Vowpal Wabbit:](https://vowpalwabbit.org/) provides a fast, flexible, online, and active learning solution that empowers you to solve complex interactive machine learning problems.

10.  Finance Dictionary  
    a. [Finance Dictionary Text](https://www.investopedia.com/financial-term-dictionary-4769738)  
    b. [RBI IFSC PARSER](https://github.com/zerodhatech/rbiparser)

11.  Generate Fake Data  
    a. [Python Faker Library](https://www.geeksforgeeks.org/python-faker-library/): This would help generate dummy data of Name, Address, Location, Bank Details, IP Address, etc.

12.  Ranking Algorithms | Decision Making Algorithms:  
    a. Learning to Rank by Xgboost/LightGBM  
    b. [Scikit-Criteria](https://scikit-criteria.readthedocs.io/en/latest/tutorial/quickstart.html) Multi-Criteria Decision making Algorithms (MCDA)

13.  Speech / Voice Analytics  
    a. [Kaldi](https://github.com/kaldi-asr/kaldi)  
    b. [PyAudioAnalysis](https://github.com/tyiannak/pyAudioAnalysis)  
    c. DeepSpeech: DeepSpeech is an open source embedded speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.  
    d. [Librosa](https://github.com/librosa/librosa): Python library for audio and music analysis
